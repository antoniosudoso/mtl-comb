## Optimizing accuracy and diversity: a multi-task approach to forecast combinations
Code to generate forecast combinations based on the paper ["Optimizing accuracy and diversity: a multi-task approach to forecast combinations"](http://arxiv.org/abs/2310.20545).


Our code is based on multiple R and Python scripts. The R scripts handle the first part of the offline phase of the meta-learner, which includes the meta-data generation process. The Python scripts manage the second part of the offline phase, which involves training the meta-learner, and then proceed with the online phase by extracting the final forecasts.

### R Scripts
Below is a list of the R scripts along with a brief description of their input and output files. For reproducibility, we recommend executing the code in an R 4.4.1 environment with the following package versions:

- `forecast` 8.22.0
- `tsutils` 0.9.4
- `tseries` 0.10-56
- `quadprog` 1.5-8
- `Matrix` 1.7-0
- `M4comp2018` 0.2.0
- `Metrics` 0.1.4
- `rlist` 0.4.6

The following scripts generate results for the M4 dataset. The user must specify the frequency (monthly, quarterly, yearly) using the variable `SERIES_TYPE`. Following the experimental setup described in the paper, we have the following .rds files: `M4_val.rds`, containing the in-sample periods for each time series, which is used to generate meta-data and train the meta-learner, and `M4.rds`, which contains the out-of-sample periods.

- **mainForecast.R**: Fits the base forecasting methods available in the pool on each time series and outputs the file `forecast_val_SERIES_TYPE.rds`, containing the forecasts for each time series during the training period.
- **mainMetric.R**: Reads the `forecast_val_SERIES_TYPE.rds` file generated by `mainForecast.R` and outputs `raw_labels_SERIES_TYPE.rds`, a file containing the matrix of forecasting errors for each training series.
- **mainDiversitySelection.R**: Generates classification labels by solving the QP-LAB optimization problem for each series. It takes `raw_labels_SERIES_TYPE.rds` as input and outputs `qp_labels_SERIES_TYPE.rds`, which contains the class labels for each series.
- **mainCreateTraining.R**: Produces the overall training dataset for the meta-learner (the deep neural network) named `series_SERIES_TYPE.rds`. This dataset includes the raw observations of the time series for the in-sample period, the matrix of forecasting errors, and the classification labels encoding accuracy and diversity information.
- **mainCreateTest.R**: Generates the test dataset for the trained meta-learner and outputs the file `series_test_SERIES_TYPE.rds`.

For the LargeST dataset, analogous scripts are provided:
- `mainForecastLargeST.R`
- `mainMetricsLargeST.R`
- `mainDiversitySelectionLargeST.R`
- `mainCreateTrainingLargeST.R`
- `mainCreateTestLargeST.R`

They follow the same logic as the M4 dataset scripts but are applied to the LargeST dataset. The dataset files `LargeST_Hourly_val.rds` and `LargeST_Daily_val.rds` contain the in-sample periods for hourly and daily time series, respectively, while dataset files `LargeST_Hourly_test.rds` and `LargeST_Daily_test.rds` contain the out-of-sample periods.

Intermediate results are stored as .rds files in the `M4` and `LargeST` folders in the repository, allowing users to execute and verify results at any point in the pipeline.

### Python Scripts
Below is a list of the Python scripts with a brief description of their input and output files. For consistency with the results presented in the paper and to avoid compatibility issues, we recommend running the code in a Python 3.9.18 environment with the following package versions:

- `rpy2` 3.4.2
- `numpy` 1.26.4
- `pandas` 2.2.1
- `tensorflow` 2.11.0
- `pip` 23.3.1
- `json5` 0.9.6
- `keras` 2.11.0
- `keras-preprocessing` 1.1.2

Scripts `networks.py` and `losses.py` implement the MTL-based meta-learner and the custom loss function, respectively.

- **mainM4.py**: Trains the meta-learner on the M4 dataset. The resulting TensorFlow model is serialized in the `saved_model_M4` folder. To execute the training procedure, use the following commands in the command line:
    - `python mainM4.py -SERIES_TYPE yearly -MAX_LEN 32 -LAMBDA 0.1`
    - `python mainM4.py -SERIES_TYPE quarterly -MAX_LEN 64 -LAMBDA 0.005`
    - `python mainM4.py -SERIES_TYPE monthly -MAX_LEN 128 -LAMBDA 0.01`
- **mainLargeST.py**: Trains the meta-learner on the LargeST dataset. The resulting TensorFlow model is serialized in the `saved_model_LargeST` folder. To execute the training procedure, use the following commands in the command line:
    - `python mainLargeST.py -SERIES_TYPE Daily -MAX_LEN 180 -LAMBDA 0.05`
    - `python mainLargeST.py -SERIES_TYPE Hourly -MAX_LEN 360 -LAMBDA 0.01`

Scripts `main_test_metalearner_M4.py` and `main_test_metalearner_LargeST.py` generate out-of-sample forecasts from the meta-learner. These scripts read the appropriate TensorFlow model and invoke the predict method, writing a matrix `f_SERIES_TYPE.csv` with rows representing the number of series and columns denoting the forecasting horizon for that frequency. Evaluation metrics such as MAPE, SMAPE, OWA, and sOWA are computed by running the function `evaluate_metrics()` in the R script `metrics.R`.
 
